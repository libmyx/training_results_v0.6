/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0529 06:49:12.481359 140185141368640 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0529 06:49:12.537645 140185141368640 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0529 06:49:12.542260 140185141368640 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-05-29 06:49:12.572851: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-29 06:49:12.576419: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.36281323]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.6035049]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.8241961]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.45689178]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.59957385]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.25357199]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.55543208]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.31954384]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58039951]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.1118288]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14189506]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.62975216]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.910504103]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.04650259]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1375401]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.99783659]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09113407]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.20389271]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.61024284]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.46048403]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30348027]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.54509366]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.08846974]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.99680769]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.43013716]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.51664901]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.44033897]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.1977787]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.4827497]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.20772934]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29435]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.81171131]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1695435]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.11079168]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13821077]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.06032515]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17492473]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.32500887]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.85313606]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.86001563]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.26919794]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.64607418]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.92967522]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.9961195]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47468483]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.28633022]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.41230929]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.72826529]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.40768433]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.93884301]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.04369104]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.41676569]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.02080762]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.85624]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33387673]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.23280573]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09997869]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.82942486]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.71705604]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.19179106]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.204579]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.5915333]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.8238951]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.26607728]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.91379809]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.04965162]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.59853244]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.31467247]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.48224235]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.28816795]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.10635197]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.75160503]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.974687219]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.06885958]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29851532]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.70813799]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.61352205]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.8986845]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.425771]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.66407442]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21203446]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.42827773]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.75717258]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.0353322]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.44911253]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.64347]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.42204881]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.12494373]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.82318556]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.11193085]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13195443]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.48073149]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14916945]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.47212362]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17284143]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.10561562]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.35162]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.55544758]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.85202169]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.23815465]
