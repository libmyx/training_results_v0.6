/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0526 09:30:20.862581 140097681938240 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0526 09:30:20.918905 140097681938240 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0526 09:30:20.923578 140097681938240 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-05-26 09:30:20.954322: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-26 09:30:20.957491: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33066082]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.666255]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.8022536]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.56516314]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.43497181]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.69708967]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.82903397]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.72408]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47244644]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.41745901]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1182915]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.73608351]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.11746991]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.63640356]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.45511937]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.78745937]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.86416566]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.97727633]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.76248813]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.43486166]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.45082986]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.56585634]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.61654353]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.2636869]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.47749877]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.46336746]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.08456039]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.93373775]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.77468169]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.61646891]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.63240612]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.01160955]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18920708]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.76535273]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27779472]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.99898863]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.670421]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.31247425]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.28928661]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.78265595]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.53650606]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.61878848]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.62395132]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.67266774]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.87553]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.18344784]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.058424]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.0737462]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.43761945]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.48844719]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.36374688]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.93536615]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.34189987]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.06748199]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33092022]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.28293467]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.48902035]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.56531715]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.88174558]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.85409284]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30268228]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.68767273]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.72130609]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.67901325]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.13528919]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.7292428]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.17015266]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.42202663]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.57873905]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.77145195]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33008039]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.36141539]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.76653659]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.63578558]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29657662]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.21674728]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.82593405]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.47240829]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.74345016]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.90763068]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.28580308]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.56387293]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.28037786]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.98045015]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.98570776]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.59460926]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.57703543]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.54428196]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.98864031]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.81717205]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27992594]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.67022896]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47394121]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.98024178]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.60408473]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.35979033]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.90508568]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.17268085]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.85387921]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.44655108]
