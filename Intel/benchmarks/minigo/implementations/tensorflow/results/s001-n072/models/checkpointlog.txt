/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0526 03:46:48.237652 140026402326336 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0526 03:46:48.295722 140026402326336 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0526 03:46:48.300403 140026402326336 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-05-26 03:46:48.331400: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-26 03:46:48.334875: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.28707254]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.5897603]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.73099148]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.14024091]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.44947314]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.43614411]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2619381]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.22082901]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.45448387]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.45098448]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2157414]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.52854681]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.36857438]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.02317381]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.12094462]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.21717453]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30217469]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.16536]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.39811039]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.47866]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.07636082]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.38175762]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.13154292]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.57014251]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.66679192]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.20086765]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.75284946]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.73957491]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.35344863]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.54292488]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.02850044]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.81578779]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14967918]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.09233952]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.992327273]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.08048439]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13557351]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.50824451]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.14048839]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.94659638]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14487636]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29189944]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.50941503]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.35173607]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.80234873]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.32443857]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.10765529]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.28732395]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33534777]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.54957271]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1259675]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.22296667]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.01316857]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.94947147]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09979284]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.37027502]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18264353]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.41223]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.46999717]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.92948365]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.24087274]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.40705693]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.37208092]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.16048741]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.86361241]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.55216169]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.48138809]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.8494885]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.44037402]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.1823287]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18255675]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.21310711]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.15721953]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.73092699]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.995006621]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.2645793]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31832695]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.9066782]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.56392932]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.13279891]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2545979]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30841696]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.57922316]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.37016559]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.0098865]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.00362062]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.81372058]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.71972299]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.65194857]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.30685806]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.52453387]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.73720455]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.7691654]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.3231864]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.3323065]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.82586527]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.20130241]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.09174681]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.37855268]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.06563091]
