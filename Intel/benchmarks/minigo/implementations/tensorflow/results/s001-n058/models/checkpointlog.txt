/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0527 22:31:50.893241 139945884796736 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0527 22:31:50.948554 139945884796736 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0527 22:31:50.953155 139945884796736 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-05-27 22:31:50.983758: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-27 22:31:50.987330: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.36050797]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.43806636]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58941543]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.20406032]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.61562622]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.8805809]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.78356874]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.6157546]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31713951]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.29735756]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.42315245]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.93831921]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13553238]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.68757629]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.19395363]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.11601639]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.3388238]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.90135]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.31588912]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.77209592]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.20976424]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.49148428]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2973156]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.05356812]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.89052415]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.00987768]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.28459048]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.42921162]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.45675778]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.38997459]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1118176]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.31522083]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09136438]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.92290211]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.23855317]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.40185]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.72115207]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.674366]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.37738323]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.33814478]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.05436659]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.42710888]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.43507826]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.90599418]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.59423065]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.17536354]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.12600315]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.13009739]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.42413008]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.60028696]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14078534]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.1842556]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.933897614]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.73262739]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.879410207]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.97086191]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.04544866]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.32752895]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.46442485]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.44500971]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21283376]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.55974603]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.89250171]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.51082921]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.45844054]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.56992483]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.96177506]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.60935259]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.91049194]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.54122591]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33653736]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.81887197]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.04315782]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.99549961]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18447554]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.24965382]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31556118]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.80733585]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.47748232]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.66136312]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.06028306]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.38176453]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.63011611]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.31722689]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.48723]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.81744099]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.16317153]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.23247194]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.19960964]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.12916279]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.346771]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.63194513]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.10591817]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.63613653]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33471131]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.68577147]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.62079871]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.23699808]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.77518]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.93170714]
