/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0602 20:25:15.901019 140240295106368 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0602 20:25:15.957818 140240295106368 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0602 20:25:15.962435 140240295106368 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-06-02 20:25:15.993196: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-06-02 20:25:15.996612: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21172583]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47741652]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.23905039]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.35698676]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.02541637]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.19100761]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.57647777]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.79163885]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17568684]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.48770475]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31895638]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.98306417]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30350471]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.70296049]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.4178493]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][8.40925407]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31714737]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.74870443]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.10756636]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.87601542]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.35684443]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.56468844]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.09748054]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.00542283]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.43510461]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.21292448]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.8345722]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.8144207]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.49786079]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.16021]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2615118]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.53414822]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2656405]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.20306969]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.26378763]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.4877882]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.8151561]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.39713]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.41901827]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.65424728]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.20147455]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47499347]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.49338639]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.1277225]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.54974711]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.36653233]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.52516]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.9392581]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29024661]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.09414291]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27965689]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.28391647]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18425822]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.29236603]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.36131394]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.02467442]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.3876375]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.49831867]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.91442513]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.79221177]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.15894783]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.36588657]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27730393]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.02900529]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.53375363]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.81360483]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21581173]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.41842413]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2144227]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.66011739]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1297518]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.40526772]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.992988408]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.95087576]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33027542]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.41128159]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.34827375]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.54698133]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.30801988]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.51334429]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.23724449]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.93319631]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.50255334]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.05203533]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.7312429]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.36375928]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.16536617]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.17769837]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.16031492]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.75309849]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1513679]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.39333]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13737]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.99919224]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.00385702]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.27084446]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31712973]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.47369814]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.60102916]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.33274555]
