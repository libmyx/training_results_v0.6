/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0526 20:07:48.330308 140640657381184 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0526 20:07:48.384802 140640657381184 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0526 20:07:48.389380 140640657381184 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-05-26 20:07:48.419826: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-26 20:07:48.423484: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.08603609]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.5277499]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.90209961]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.17535567]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.84251523]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.81802058]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.66826844]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.09909391]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.35057843]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.52534294]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27635074]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.22665644]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.25855267]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.01112175]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17421818]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.97219372]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.52715766]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.9240346]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.32859755]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.83195615]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.23207963]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30892444]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.25396359]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.93092406]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.50568509]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.71166515]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31984937]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.4578414]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.10936725]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.75310731]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21445227]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.26893902]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.98977232]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.94064951]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.02261531]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.21806431]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.0703814]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.88178]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.35194397]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.69183874]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13488519]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.57093656]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.64605975]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.93494654]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.59125674]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.37409711]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.77549648]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.90459037]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.11142015]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.86298585]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.28566277]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.49645376]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.03786874]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.70912]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.35185027]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.03345585]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.34470212]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.88849115]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.58275151]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.32189417]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.1160289]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.44601703]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.00542974]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.02061]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.51523221]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.31881404]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.53039873]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.82271671]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.26751721]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.05975771]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.24282944]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.58013248]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.01707792]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.32946205]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.04568648]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.00029325]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21122491]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.27343655]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.63145089]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.54417753]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27231622]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47444773]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58930719]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.53880358]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.46279418]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.16176057]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.80096877]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.6892662]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.73134792]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.26792574]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.19222605]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.61241388]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17270744]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.4655261]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33776152]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.15803432]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31655407]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.73678207]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.42139149]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.80132294]
