/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0526 01:41:48.483458 140519339071296 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0526 01:41:48.538998 140519339071296 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0526 01:41:48.543572 140519339071296 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-05-26 01:41:48.573934: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-26 01:41:48.577592: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21678793]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.37116253]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.38085222]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.15918851]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.09524226]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.7341876]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.24557483]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.85827327]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09444666]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.9799931]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.10089302]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.92128468]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.972837806]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.24130726]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.00784838]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.10583544]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.21923697]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.81247711]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.94234252]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.00880527]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.07220924]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.56634283]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.95773494]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.1291697]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58432579]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.61616969]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.25058842]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.94372368]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29948723]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.69381332]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18866348]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.67219114]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.00672579]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.47666836]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.37250221]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.08296156]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.44772255]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.39142036]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.08142328]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.00525761]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.18841481]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.68862176]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.51852453]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.56989169]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.90581048]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.27819395]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.37412405]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.0236249]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.16499841]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.04369974]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.02590823]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.09362888]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.0565325]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.76459742]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.01412523]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.44571304]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14474237]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.57486105]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.47193384]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.30825043]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.27995336]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.84282982]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.61864603]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.26342368]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.71074808]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.44775486]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.45082688]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.1194911]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.26124465]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.90434742]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.12212896]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.85685444]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58313477]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.88244534]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29655063]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.36090231]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.15367413]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.4209981]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.68313289]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.36952806]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09547758]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.4159193]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.64694548]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.38149571]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.74994481]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.63659835]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.56926298]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.74991822]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.77103901]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.58543825]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.2148422]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.36347246]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.25800824]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.26351118]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33026683]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.42362309]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.25015628]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.7764039]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.5828023]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.1339]
