/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/u41625/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0602 07:04:55.262068 140669379839808 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:140: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0602 07:04:55.317813 140669379839808 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0602 07:04:55.322496 140669379839808 deprecation.py:323] From /home/u41625/training_results_v0.6/Intel/benchmarks/minigo/implementations/tensorflow/preprocessing.py:222: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
2020-06-02 07:04:55.353471: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-06-02 07:04:55.356733: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.16298807]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.6574322]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.7197094]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.31192708]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.31360149]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.44710493]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.47853494]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.54614449]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.3638202]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.29674196]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.06317759]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.75968122]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17784154]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.89821672]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.3208071]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.30477905]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.37725151]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.46128511]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.65852261]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.15042019]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.09540343]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.43431509]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.94090664]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.84596288]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.50773799]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.84952831]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.60149741]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.51105022]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.38610184]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.31969881]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.13188219]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.79429054]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.46255374]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.3692379]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.29953599]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.17104197]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.07011902]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][7.47141123]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.31166053]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.66213298]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.22551465]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.24729681]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.62262011]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.91075242]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58206356]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.03258848]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.69132161]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.5392344]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.26547134]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.03148508]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14780819]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.31544113]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.8700369]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.66024923]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][0.984192431]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.13351]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.03246033]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.33726788]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.14899]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.60691738]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.17733026]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.7056284]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.03989291]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.93819666]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.99758399]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.50918651]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.20135665]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.77569294]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.83566785]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.09330893]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.30543959]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.91634464]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.12779486]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.03797054]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.10404313]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.84086037]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.33353245]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][8.87199306]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.18870711]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.53817129]
;conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.32961702]
;conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.32180703]
;conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.58067703]
;conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][2.17698359]
;conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.90803242]
;conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.50038743]
;conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.31424439]
;conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.68965125]
;conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.14995396]
;conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.90773678]
;conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.20482624]
;conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.31845617]
;conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.37215579]
;conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][4.94052505]
;conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.02603006]
;conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][5.3465147]
;conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][1.15587199]
;conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][6.41457605]
;conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.2066195]
;conv2d_20/Conv2D_eightbit_requant_range__print__;__requant_min_max:[0][3.95783186]
